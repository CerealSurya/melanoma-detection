{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27674,"status":"ok","timestamp":1719456570006,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"jdTffiUFZpfL","outputId":"7b59f530-8904-486c-e2f1-23eab2d86f9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":116,"status":"ok","timestamp":1719456571645,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"nhHrD1FlZ3G_"},"outputs":[],"source":["cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","BATCH_SIZE = 8\n","EPOCHS = 50\n","noise_dim = 100\n","num_examples_to_generate = 16\n","img_height=224\n","img_width=224"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1458,"status":"ok","timestamp":1719448446542,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"Wd8zaPVi549l","outputId":"49224498-1c35-479f-9f5a-056345cab8ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2298 files belonging to 1 classes.\n"]}],"source":["dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","        '/content/drive/My Drive/imgs_part_1', #Pad-UFES-20\n","        label_mode=None,  # Since it's an unconditional generator, we don't need labels\n","        image_size=(img_height, img_width),  # Resize images to the target size\n","        batch_size=BATCH_SIZE  # We'll handle batching later\n","    )\n","\n","# Normalize images to [-1, 1]\n","dataset = dataset.map(lambda x: (x - 127.5) / 127.5)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":651,"status":"ok","timestamp":1719456573817,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"hzuXFvEn6BQr"},"outputs":[],"source":["def build_generator():\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(14*14*512, use_bias=False, input_shape=(100,)))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Reshape((14, 14, 512)))\n","    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n","    return model\n","\n","generator = build_generator()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":266,"status":"ok","timestamp":1719456574766,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"SP5MPcKM6HTS"},"outputs":[],"source":["def build_discriminator():\n","    model = tf.keras.Sequential()\n","    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[224, 224, 3]))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","    model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same'))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(1))\n","    return model\n","\n","discriminator = build_discriminator()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":136,"status":"ok","timestamp":1719456576089,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"XibpIaoh6Mgy"},"outputs":[],"source":["def discriminator_loss(real_output, fake_output):\n","    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n","    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    return total_loss\n","\n","def generator_loss(fake_output):\n","    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n","    return loss\n","\n","generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"elapsed":3002,"status":"ok","timestamp":1719456751309,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"vJrBaBbHpb7Y","outputId":"7470d0d0-7b16-4930-fe4d-74c1a322c5f3"},"outputs":[],"source":["def sample_images(generator, image_grid_rows=3, image_grid_columns=3):\n","\n","    satisfied = False\n","    images = []\n","    while not satisfied:\n","      print(len(images))\n","      noise = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, 100))\n","      generated_images = generator(noise, training=False)\n","      #generated_images = 0.5 * generated_images + 0.5\n","\n","      input_layer = tf.keras.Input(shape=(224, 224, 3))\n","      output_layer = discriminator(input_layer)\n","      output_layer = tf.keras.activations.sigmoid(output_layer)\n","\n","      # Create a new model\n","      sigDiscriminator = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n","      test = sigDiscriminator(generated_images, training=False).numpy()\n","\n","      for n in range(image_grid_rows * image_grid_columns):\n","        if test[n][0] < 0.5:\n","          images.append(generated_images[n])\n","      if len(images) >= image_grid_rows * image_grid_columns:\n","        satisfied = True\n","\n","\n","    fig, axs = plt.subplots(image_grid_rows, image_grid_columns, figsize=(4, 4), sharey=True, sharex=True)\n","    cnt = 0\n","    #plt.imshow(images[0])\n","    for i in range(image_grid_rows):\n","        for j in range(image_grid_columns):\n","            axs[i, j].imshow(images[cnt])\n","            axs[i, j].axis('off')\n","            cnt += 1\n","    plt.show()\n","\n","sample_images(generator)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":330,"status":"ok","timestamp":1719448456420,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"qQGvPbOo6T-4"},"outputs":[],"source":["#@tf.function\n","def train_step(images, epoch):\n","    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        generated_images = generator(noise, training=True)\n","        real_output = discriminator(images, training=True)\n","        fake_output = discriminator(generated_images, training=True)\n","\n","        gen_loss = generator_loss(fake_output)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","\n","    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n","    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n","    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n","\n","    return gen_loss, disc_loss"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1719456580778,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"xy3P067-709D"},"outputs":[],"source":["gen_dir = \"/content/drive/My Drive/checkpointsGen/\"\n","checkpoint_prefix = os.path.join(gen_dir, \"ckpt\")\n","\n","\n","genCP = tf.train.Checkpoint(optimizer=generator_optimizer, model=generator)\n","genCheckpointer = tf.train.CheckpointManager(genCP, gen_dir, max_to_keep=3)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":509,"status":"ok","timestamp":1719456582402,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"qeI-jbDf97OE"},"outputs":[],"source":["disc_dir = \"/content/drive/My Drive/checkpointDisc/\"\n","checkpoint_prefix = os.path.join(gen_dir, \"ckpt\")\n","\n","discCP = tf.train.Checkpoint(optimizer=discriminator_optimizer, model=discriminator)\n","discCheckpointer = tf.train.CheckpointManager(discCP, disc_dir, max_to_keep=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7665,"status":"ok","timestamp":1719456730179,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"9aVdsrhw9Qp2","outputId":"104fc22c-b03f-4573-8889-50811b27a7e1"},"outputs":[],"source":["latest_checkpoint = genCheckpointer.latest_checkpoint\n","if latest_checkpoint:\n","    #genCP.restore(latest_checkpoint)\n","    genCP.restore(\"/content/drive/My Drive/checkpointsGen/ckpt-12\") #.assert_consumed()\n","    print(f\"Generator loaded from {latest_checkpoint}\")\n","else:\n","    print(\"Generator training from scratch.\")\n","\n","latest_checkpoint = discCheckpointer.latest_checkpoint\n","if latest_checkpoint:\n","    #discCP.restore(latest_checkpoint)\n","    discCP.restore(\"/content/drive/My Drive/checkpointDisc/ckpt-12\") #.assert_consumed()\n","    print(f\"Discriminator loaded from {latest_checkpoint}\")\n","else:\n","    print(\"Discriminator training from scratch.\")"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":319,"status":"ok","timestamp":1719448475590,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"Ee5HJvjX6YxQ"},"outputs":[],"source":["def train(dataset, epochs):\n","  for epoch in range(epochs):\n","    for image_batch in dataset:\n","        gen_loss, disc_loss = train_step(image_batch, epoch)\n","        print(f\"\\n\\nEpoch: {epoch + 1} | Generator Loss: {gen_loss} | Discriminator Loss: {disc_loss}\")\n","\n","    print(f\"\\nEnd of epoch {epoch + 1}\\n\")\n","    if (epoch + 1) % 10 == 0:\n","      genCheckpointer.save()\n","      discCheckpointer.save()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6573749,"status":"error","timestamp":1719455059124,"user":{"displayName":"Cereal Surya","userId":"15512103411705819032"},"user_tz":420},"id":"lIZ5cnhf6aGO","outputId":"05375502-2575-4dbc-ef95-368b0a6c9c53"},"outputs":[],"source":["train(dataset, EPOCHS)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOH0j9Uu1u3MX3dEUxP5z1N","mount_file_id":"1t035pSJRoNrmaQAKMZLFZsGEN6TTR-eA","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
